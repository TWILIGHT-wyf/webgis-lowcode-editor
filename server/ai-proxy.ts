/**
 * AI ä»£ç†æœåŠ¡å™¨ (TypeScript) - å¤šæ¨¡å‹ç‰ˆæœ¬
 * æ”¯æŒ Geminiã€OpenAIã€Claudeã€é€šä¹‰åƒé—®ã€DeepSeek ç­‰å¤šå®¶ AI
 *
 * ä½¿ç”¨æ–¹æ³•:
 *   npm start -- --key=ä½ çš„APIå¯†é’¥ --provider=gemini
 *
 * æ”¯æŒçš„ provider:
 *   - gemini   (Google Gemini) - éœ€è¦ä»£ç†
 *   - openai   (OpenAI GPT) - éœ€è¦ä»£ç†
 *   - claude   (Anthropic Claude) - éœ€è¦ä»£ç†
 *   - qwen     (é˜¿é‡Œé€šä¹‰åƒé—®) - å›½å†…ç›´è¿
 *   - deepseek (DeepSeek) - å›½å†…ç›´è¿
 *
 * ä»£ç†è®¾ç½®ï¼ˆClash Verge é»˜è®¤ç«¯å£ 7897ï¼‰:
 *   npm start -- --key=xxx --provider=gemini --proxy=http://127.0.0.1:7897
 */

import express, { type Request, type Response as ExpressResponse } from 'express'
import cors from 'cors'
import dotenv from 'dotenv'
import { parseArgs } from 'node:util'
import { ProxyAgent, fetch as undiciFetch } from 'undici'

// ==================== å‘½ä»¤è¡Œå‚æ•°è§£æ ====================
const { values: args } = parseArgs({
  options: {
    key: { type: 'string', short: 'k' },
    provider: { type: 'string', short: 'P' },
    model: { type: 'string', short: 'm' },
    port: { type: 'string', short: 'p' },
    proxy: { type: 'string' },
  },
  strict: false,
})

// ä»…å½“æ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°æ—¶æ‰åŠ è½½ .env
if (!args.key && !process.env.AI_API_KEY) {
  dotenv.config()
}

// ==================== ç±»å‹å®šä¹‰ ====================
interface Message {
  role: 'system' | 'user' | 'assistant'
  content: string
}

interface GenerateRequest {
  messages: Message[]
  temperature?: number
  max_tokens?: number
  provider?: string
  model?: string
}

interface GenerationConfig {
  temperature: number
  maxTokens: number
}

type ProviderName = 'gemini' | 'openai' | 'claude' | 'qwen' | 'deepseek'

interface ProviderConfig {
  name: string
  baseUrl: string
  defaultModel: string
  models: string[]
  needsProxy: boolean
  transform: {
    request: (messages: Message[], model: string, config: GenerationConfig) => unknown
    response: (data: unknown) => string
  }
}

// ==================== å¤šæ¨¡å‹é…ç½® ====================
const PROVIDERS: Record<ProviderName, ProviderConfig> = {
  // Google Gemini
  gemini: {
    name: 'Google Gemini',
    baseUrl: 'https://generativelanguage.googleapis.com/v1beta/models',
    defaultModel: 'gemini-2.0-flash',
    models: ['gemini-2.0-flash', 'gemini-2.0-flash-lite', 'gemini-1.5-flash', 'gemini-1.5-pro'],
    needsProxy: true,
    transform: {
      request: (messages, _model, config) => {
        const systemMsg = messages.find((m) => m.role === 'system')
        const userMsgs = messages.filter((m) => m.role !== 'system')
        return {
          contents: userMsgs.map((msg) => ({
            role: msg.role === 'assistant' ? 'model' : 'user',
            parts: [{ text: msg.content }],
          })),
          systemInstruction: systemMsg ? { parts: [{ text: systemMsg.content }] } : undefined,
          generationConfig: {
            temperature: config.temperature,
            maxOutputTokens: config.maxTokens,
          },
        }
      },
      response: (data: unknown) => {
        const d = data as { candidates?: Array<{ content?: { parts?: Array<{ text?: string }> } }> }
        return d.candidates?.[0]?.content?.parts?.[0]?.text || ''
      },
    },
  },

  // OpenAI
  openai: {
    name: 'OpenAI',
    baseUrl: 'https://api.openai.com/v1',
    defaultModel: 'gpt-4o-mini',
    models: ['gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo', 'gpt-3.5-turbo'],
    needsProxy: true,
    transform: {
      request: (messages, model, config) => ({
        model,
        messages,
        temperature: config.temperature,
        max_tokens: config.maxTokens,
      }),
      response: (data: unknown) => {
        const d = data as { choices?: Array<{ message?: { content?: string } }> }
        return d.choices?.[0]?.message?.content || ''
      },
    },
  },

  // Anthropic Claude
  claude: {
    name: 'Anthropic Claude',
    baseUrl: 'https://api.anthropic.com/v1',
    defaultModel: 'claude-3-5-sonnet-20241022',
    models: ['claude-3-5-sonnet-20241022', 'claude-3-5-haiku-20241022', 'claude-3-opus-20240229'],
    needsProxy: true,
    transform: {
      request: (messages, model, config) => {
        const systemMsg = messages.find((m) => m.role === 'system')
        const userMsgs = messages.filter((m) => m.role !== 'system')
        return {
          model,
          max_tokens: config.maxTokens,
          system: systemMsg?.content,
          messages: userMsgs.map((m) => ({ role: m.role, content: m.content })),
        }
      },
      response: (data: unknown) => {
        const d = data as { content?: Array<{ text?: string }> }
        return d.content?.[0]?.text || ''
      },
    },
  },

  // é˜¿é‡Œé€šä¹‰åƒé—®ï¼ˆå›½å†…ç›´è¿ï¼‰
  qwen: {
    name: 'é€šä¹‰åƒé—®',
    baseUrl: 'https://dashscope.aliyuncs.com/compatible-mode/v1',
    defaultModel: 'qwen-turbo',
    models: ['qwen-turbo', 'qwen-plus', 'qwen-max', 'qwen-long'],
    needsProxy: false,
    transform: {
      request: (messages, model, config) => ({
        model,
        messages,
        temperature: config.temperature,
        max_tokens: config.maxTokens,
      }),
      response: (data: unknown) => {
        const d = data as { choices?: Array<{ message?: { content?: string } }> }
        return d.choices?.[0]?.message?.content || ''
      },
    },
  },

  // DeepSeekï¼ˆå›½å†…ç›´è¿ï¼‰
  deepseek: {
    name: 'DeepSeek',
    baseUrl: 'https://api.deepseek.com/v1',
    defaultModel: 'deepseek-chat',
    models: ['deepseek-chat', 'deepseek-coder'],
    needsProxy: false,
    transform: {
      request: (messages, model, config) => ({
        model,
        messages,
        temperature: config.temperature,
        max_tokens: config.maxTokens,
      }),
      response: (data: unknown) => {
        const d = data as { choices?: Array<{ message?: { content?: string } }> }
        return d.choices?.[0]?.message?.content || ''
      },
    },
  },
}

// ==================== é…ç½® ====================
const CONFIG = {
  apiKey: String(args.key || process.env.AI_API_KEY || ''),
  provider: String(args.provider || process.env.AI_PROVIDER || 'gemini') as ProviderName,
  model: String(args.model || process.env.AI_MODEL || ''),
  port: parseInt(String(args.port || process.env.PROXY_PORT || '3001'), 10),
  proxy: String(args.proxy || process.env.HTTPS_PROXY || 'http://127.0.0.1:7897'),
}

// éªŒè¯ provider
if (!PROVIDERS[CONFIG.provider]) {
  console.error(`âŒ é”™è¯¯: ä¸æ”¯æŒçš„ provider "${CONFIG.provider}"`)
  console.log(`ğŸ“ æ”¯æŒçš„ provider: ${Object.keys(PROVIDERS).join(', ')}`)
  process.exit(1)
}

// æ£€æŸ¥ API Key
if (!CONFIG.apiKey) {
  console.error('âŒ é”™è¯¯: æœªæä¾› API å¯†é’¥')
  console.log('')
  console.log('ğŸ“ ä½¿ç”¨æ–¹æ³•:')
  console.log('   npm start -- --key=ä½ çš„APIå¯†é’¥ --provider=gemini')
  console.log('')
  console.log('ğŸ“¦ æ”¯æŒçš„ provider:')
  Object.entries(PROVIDERS).forEach(([key, p]) => {
    console.log(`   ${key.padEnd(10)} - ${p.name} (${p.needsProxy ? 'éœ€è¦ä»£ç†' : 'å›½å†…ç›´è¿'})`)
  })
  process.exit(1)
}

const currentProvider = PROVIDERS[CONFIG.provider]
const currentModel = CONFIG.model || currentProvider.defaultModel

// ==================== Express æœåŠ¡å™¨ ====================
const app = express()
app.use(cors())
app.use(express.json())

function buildUrl(
  providerName: ProviderName,
  provider: ProviderConfig,
  model: string,
  apiKey: string,
): string {
  switch (providerName) {
    case 'gemini':
      return `${provider.baseUrl}/${model}:generateContent?key=${apiKey}`
    case 'openai':
    case 'qwen':
    case 'deepseek':
      return `${provider.baseUrl}/chat/completions`
    case 'claude':
      return `${provider.baseUrl}/messages`
    default:
      return provider.baseUrl
  }
}

function buildHeaders(providerName: ProviderName, apiKey: string): Record<string, string> {
  const headers: Record<string, string> = { 'Content-Type': 'application/json' }
  switch (providerName) {
    case 'gemini':
      break
    case 'claude':
      headers['x-api-key'] = apiKey
      headers['anthropic-version'] = '2023-06-01'
      break
    default:
      headers['Authorization'] = `Bearer ${apiKey}`
  }
  return headers
}

/**
 * AI ç”Ÿæˆæ¥å£
 * POST /api/ai/generate
 */
app.post('/api/ai/generate', async (req: Request, res: ExpressResponse): Promise<void> => {
  try {
    const {
      messages,
      temperature = 0.7,
      max_tokens = 4096,
      provider: reqProvider,
      model: reqModel,
    } = req.body as GenerateRequest

    if (!messages || !Array.isArray(messages)) {
      res.status(400).json({ error: 'messages å‚æ•°å¿…é¡»æ˜¯æ•°ç»„' })
      return
    }

    const useProvider = (reqProvider as ProviderName) || CONFIG.provider
    const providerConfig = PROVIDERS[useProvider] || currentProvider
    const useModel =
      reqModel || (useProvider === CONFIG.provider ? currentModel : providerConfig.defaultModel)

    console.log(`[${new Date().toISOString()}] è¯·æ±‚ - Provider: ${useProvider}, Model: ${useModel}`)

    const url = buildUrl(useProvider, providerConfig, useModel, CONFIG.apiKey)
    const headers = buildHeaders(useProvider, CONFIG.apiKey)
    const body = providerConfig.transform.request(messages, useModel, {
      temperature,
      maxTokens: max_tokens,
    })

    let response: Response

    if (providerConfig.needsProxy && CONFIG.proxy) {
      // ä½¿ç”¨ undici çš„ ProxyAgent è¿›è¡Œä»£ç†è¯·æ±‚
      console.log(`[${new Date().toISOString()}] ä½¿ç”¨ä»£ç†: ${CONFIG.proxy}`)
      const proxyAgent = new ProxyAgent(CONFIG.proxy)
      response = (await undiciFetch(url, {
        method: 'POST',
        headers,
        body: JSON.stringify(body),
        dispatcher: proxyAgent,
      })) as unknown as Response
    } else {
      // å›½å†…ç›´è¿ï¼Œä½¿ç”¨åŸç”Ÿ fetch
      response = await fetch(url, {
        method: 'POST',
        headers,
        body: JSON.stringify(body),
      })
    }

    if (!response.ok) {
      const errorText = await response.text()
      console.error(`[${new Date().toISOString()}] API é”™è¯¯ (${response.status}):`, errorText)
      res
        .status(response.status)
        .json({ error: `API è¯·æ±‚å¤±è´¥: ${response.status}`, details: errorText })
      return
    }

    const data = await response.json()

    if ((data as { error?: { message?: string } }).error) {
      const errMsg = (data as { error: { message?: string } }).error.message || 'Unknown error'
      console.error(`[${new Date().toISOString()}] ${providerConfig.name} é”™è¯¯:`, errMsg)
      res.status(500).json({ error: errMsg })
      return
    }

    const content = providerConfig.transform.response(data)
    console.log(`[${new Date().toISOString()}] å“åº”æˆåŠŸï¼Œé•¿åº¦: ${content.length}`)

    res.json({
      choices: [{ message: { role: 'assistant', content } }],
      provider: useProvider,
      model: useModel,
    })
  } catch (error) {
    const err = error as Error
    console.error(`[${new Date().toISOString()}] æœåŠ¡å™¨é”™è¯¯:`, err)
    res.status(500).json({ error: 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯', message: err.message })
  }
})

/**
 * è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
 * GET /api/ai/models
 */
app.get('/api/ai/models', (_req: Request, res: ExpressResponse) => {
  const models = Object.entries(PROVIDERS).map(([key, p]) => ({
    provider: key,
    name: p.name,
    models: p.models,
    defaultModel: p.defaultModel,
    needsProxy: p.needsProxy,
  }))
  res.json({ models, current: { provider: CONFIG.provider, model: currentModel } })
})

/**
 * å¥åº·æ£€æŸ¥æ¥å£
 * GET /api/health
 */
app.get('/api/health', (_req: Request, res: ExpressResponse) => {
  res.json({
    status: 'ok',
    provider: CONFIG.provider,
    providerName: currentProvider.name,
    model: currentModel,
    proxy: currentProvider.needsProxy ? CONFIG.proxy : 'not needed',
    timestamp: new Date().toISOString(),
  })
})

// ==================== å¯åŠ¨æœåŠ¡å™¨ ====================
app.listen(CONFIG.port, () => {
  console.log('â•'.repeat(55))
  console.log('ğŸš€ AI ä»£ç†æœåŠ¡å™¨å·²å¯åŠ¨ (å¤šæ¨¡å‹ç‰ˆ)')
  console.log('â•'.repeat(55))
  console.log(`ğŸ“ åœ°å€: http://localhost:${CONFIG.port}`)
  console.log(`ğŸ¤– Provider: ${currentProvider.name}`)
  console.log(`ğŸ“¦ Model: ${currentModel}`)
  console.log(`ğŸ”‘ API Key: ${CONFIG.apiKey.slice(0, 8)}...${CONFIG.apiKey.slice(-4)}`)
  if (currentProvider.needsProxy) {
    console.log(`ğŸŒ ä»£ç†: ${CONFIG.proxy}`)
  } else {
    console.log(`ğŸŒ ä»£ç†: ä¸éœ€è¦ (å›½å†…ç›´è¿)`)
  }
  console.log('â•'.repeat(55))
  console.log('ğŸ“ API ç«¯ç‚¹:')
  console.log(`   POST http://localhost:${CONFIG.port}/api/ai/generate`)
  console.log(`   GET  http://localhost:${CONFIG.port}/api/ai/models`)
  console.log('â•'.repeat(55))
  console.log('ğŸ’¡ æ”¯æŒçš„ Provider:')
  Object.entries(PROVIDERS).forEach(([key, p]) => {
    const tag = p.needsProxy ? 'ğŸŒ' : 'ğŸ‡¨ğŸ‡³'
    console.log(`   ${tag} ${key.padEnd(10)} - ${p.name}`)
  })
  console.log('â•'.repeat(55))
})
